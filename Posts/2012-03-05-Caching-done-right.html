<p>I was trolling on twitter Saturday, when I saw tweet by <a href="https://twitter.com/#!/nkohari" target="_blank">Nate Kohari</a> and some answers :</p>  <p>&#160;</p>  <p><a href="https://twitter.com/#!/nkohari/status/175994006562545667" target="_blank"><img style="background-image: none; border-bottom: 0px; border-left: 0px; padding-left: 0px; padding-right: 0px; display: inline; border-top: 0px; border-right: 0px; padding-top: 0px" title="image" border="0" alt="image" src="http://thinkbeforecoding.com/public/Windows-Live-Writer/fecbc39c51a4_B849/image_5.png" width="531" height="372" /></a>    <br /></p>  <p>I immediately thought :</p>  <blockquote>   <p>If you have one problem and use cache to solve it, you now have two problems.</p> </blockquote>  <p>&#160;</p>  <p>Where’s the problem ?</p>  <p>&#160;</p>  <p>The time to retrieve the data is not negligible due to frequency of request and/or time taken by calculation + data access. So we put data to cache so that we don’t have to endure this time on each call.</p>  <p>&#160;</p>  <p>But then comes the problem of cache expiration:</p>  <ul>   <li>We can use a duration.. but what is the acceptable delay ?</li>    <li>We can make a check to original data to check if it has changed. It’s more accurate, but incurs a new data access.</li> </ul>  <p>Moreover, checking if it changed is often not enough, we also need to find what changed. </p>  <p>&#160;</p>  <p>And deriving what happened from state is basically <strong>reverse engineering</strong>. I’m an engineer. <strong>I prefer forward engineering</strong>. </p>  <p>&#160;</p>  <p>&#160;</p>  <h1>Let’s do it forward</h1>  <p>&#160;</p>  <p>It’s actually easy, it’s the whole point of CQRS.</p>  <p>&#160;</p>  <p>Let’s build a system that raises Domain Events, and we can <strong>denormalize</strong> events to a <strong>Persistent View Model</strong>.</p>  <p>&#160;</p>  <p>We just have to listen to events and change the representation we want to send to the users:</p>  <ul>   <li>The events contain everything we need to do fine grained updates easily. </li>    <li>We can can compute denormalizations asynchronously if it’s time consuming</li>    <li>We can store it in a relational database, a document database, or in memory</li>    <li>We can choose any form of denormalization since it’s a denormalization (object graph, but also flat string, json, html …)</li>    <li>It will be up to date quickly because it will be updated when the original data changed</li>    <li>The first client that makes a request after a change will not endure a cache miss that can be long to process since computing is done on change, and not on request.</li> </ul>  <p>A good way to Keep It Simple, Stupid!</p>